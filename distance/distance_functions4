from scipy.spatial.distance import jensenshannon, braycurtis
from scipy.stats import entropy
import numpy as np
import fastdtw

# Define example probability distributions for JS Divergence and Bhattacharyya Distance
P = np.array([0.2, 0.3, 0.5])
Q = np.array([0.1, 0.4, 0.5])

# Jensen-Shannon Divergence (Symmetric KL Divergence)
js_divergence = jensenshannon(P, Q)

# Bhattacharyya Distance (similar to Jensen-Shannon but using sqrt product)
bhattacharyya_distance = -np.log(np.sum(np.sqrt(P * Q)))

# Example for Bray-Curtis Distance
braycurtis_distance = braycurtis(P, Q)

# Placeholder for Dynamic Time Warping Distance (as fastdtw is unavailable)
dtw_distance = "DTW computation requires fastdtw package"

# Display results
distance_results_fixed = {
    "Jensen-Shannon Divergence": js_divergence,
    "Bhattacharyya Distance": bhattacharyya_distance,
    "Dynamic Time Warping Distance": dtw_distance,
    "Bray-Curtis Distance": braycurtis_distance
}

# Convert to DataFrame for better visualization
df_distance_results_fixed = pd.DataFrame(list(distance_results_fixed.items()), columns=["Distance Measure", "Value"])

# Display results
df_distance_results_fixed
